{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 21,
>>>>>>> a0d8df4fb78529c533d335cf14211b3ba57603fd
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shared.utils import load_data\n",
    "from datasets import preprocess_dataset, datasets_types\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import beta as beta_dist\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, recall_score, roc_auc_score\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AntonioPayá\\Desktop\\Repos-Doctorado\\apollon\\shared\\utils\\load.py:24: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado\n",
      "Loading new data\n",
<<<<<<< HEAD
      "labels: {'FTP-Patator', 'Web Attack � Sql Injection', 'SSH-Patator', 'Web Attack � XSS', 'Web Attack � Brute Force', 'Infiltration'}\n",
=======
      "labels: {'DrDoS_MSSQL'}\n",
>>>>>>> a0d8df4fb78529c533d335cf14211b3ba57603fd
      "Dataset Preprocesado\n"
     ]
    }
   ],
   "source": [
    "load_dataset = False\n",
<<<<<<< HEAD
    "name = \"CIC-IDS_2017_MAB\"\n",
=======
    "name = \"CIC-IDS_2019_MAB\"\n",
>>>>>>> a0d8df4fb78529c533d335cf14211b3ba57603fd
    "if not load_dataset:\n",
    "    # Preprocesar el dataset\n",
    "    \"\"\"      \"\"\"\n",
    "    df = load_data(\n",
    "        [\n",
    "            \"./shared/data/CIC_2019/DrDoS_MSSQL.csv\"\n",
    "        ],\n",
    "        seed\n",
    "    )\n",
    "    print(\"Dataset cargado\")\n",
    "    df_preprocessed = preprocess_dataset(\n",
    "        df, save=True, dataset_type=\"CIC_2019\", seed=seed, load=load_dataset, name_save=name, name_load=name)\n",
    "    print(\"Dataset Preprocesado\")\n",
    "else:\n",
    "    df_preprocessed = preprocess_dataset(\n",
    "        pd.DataFrame(), save=True, dataset_type=\"CIC_2019\", seed=seed, load=load_dataset, name_save=name, name_load=name)\n",
    "    print(\"Dataset Preprocesado\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(\n",
    "            hidden_layer_sizes=(32),\n",
    "            max_iter=200,\n",
    "            verbose=False,\n",
    "            random_state=seed,\n",
    "            batch_size=200,\n",
    "            early_stopping=True,\n",
    "            activation='tanh',\n",
    "            solver='adam'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
=======
   "execution_count": 23,
>>>>>>> a0d8df4fb78529c533d335cf14211b3ba57603fd
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBanditThompsonSampling:\n",
    "\n",
    "    def __init__(self, n_arms, n_clusters):\n",
    "        self.n_arms = n_arms\n",
    "        self.n_clusters = n_clusters\n",
    "        self.arms = [RandomForestClassifier(), DecisionTreeClassifier(),\n",
    "                     GaussianNB(), LogisticRegression(), mlp]\n",
    "        self.cluster_centers = None\n",
    "        self.cluster_assignments = None\n",
    "        self.reward_sums = {}\n",
    "        for cluster in range(n_clusters):\n",
    "            self.reward_sums[cluster] = np.zeros(n_arms)\n",
    "        self.alpha = np.ones(self.n_arms)\n",
    "        self.beta = np.ones(self.n_arms)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters)\n",
    "        self.cluster_assignments = kmeans.fit_predict(X_train)\n",
    "        self.cluster_centers = kmeans.cluster_centers_\n",
    "        # Print the number of samples in each cluster\n",
    "\n",
    "        for i in range(self.n_clusters):\n",
    "            print('Cluster {}: {}'.format(\n",
    "                i, np.sum(self.cluster_assignments == i)))\n",
    "            cluster_mask = self.cluster_assignments == i\n",
    "            cluster_X_train = X_train[cluster_mask]\n",
    "            cluster_y_train = y_train[cluster_mask]\n",
    "            for arm in range(self.n_arms):\n",
    "                print('Training arm {} on cluster {}'.format(arm, i))\n",
    "                arm_mask = cluster_y_train == arm\n",
    "                arm_X_train = cluster_X_train[arm_mask]\n",
    "                arm_y_train = cluster_y_train[arm_mask]\n",
    "                if len(arm_X_train) > 0 and len(np.unique(arm_y_train)) > 1:\n",
    "                    self.arms[arm].fit(arm_X_train, arm_y_train)\n",
    "                else:\n",
    "                    self.arms[arm].fit(X_train, y_train)\n",
    "\n",
    "        # Set the arms rewards for each cluster\n",
    "        for i in range(self.n_clusters):\n",
    "            cluster_mask = self.cluster_assignments == i\n",
    "            cluster_X_test = X_train[cluster_mask]\n",
    "            cluster_y_test = y_train[cluster_mask]\n",
    "            for arm in range(self.n_arms):\n",
    "                print('Setting reward_sums arm {} on cluster {}'.format(arm, i))\n",
    "                arm_mask = cluster_y_test == arm\n",
    "                arm_X_test = cluster_X_test[arm_mask]\n",
    "                arm_y_test = cluster_y_test[arm_mask]\n",
    "                if len(arm_X_test) > 0:\n",
    "                    arm_y_pred = self.arms[arm].predict(arm_X_test)\n",
    "                    self.reward_sums[i][arm] = np.mean(\n",
    "                        arm_y_pred == arm_y_test)\n",
    "\n",
    "    def select_arm(self, cluster):\n",
    "        # Select the arm with the highest reward\n",
    "        theta = np.zeros(self.n_arms)\n",
    "        for arm in range(self.n_arms):\n",
    "            theta[arm] = np.random.beta(self.alpha[arm] + self.reward_sums[cluster]\n",
    "                                        [arm], self.beta[arm] + 1 - self.reward_sums[cluster][arm])\n",
    "        return np.argmax(theta)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Select the arm for each sample\n",
    "        arms = np.zeros(len(X_test))\n",
    "        for i in range(len(X_test)):\n",
    "            cluster = np.argmin(np.linalg.norm(\n",
    "                self.cluster_centers - X_test[i], axis=1))\n",
    "            arms[i] = self.select_arm(cluster)\n",
    "        # Predict using the selected arm\n",
    "        y_pred = np.zeros(len(X_test))\n",
    "        for arm in range(self.n_arms):\n",
    "            arm_mask = arms == arm\n",
    "            arm_X_test = X_test[arm_mask]\n",
    "            if len(arm_X_test) > 0:\n",
    "                y_pred[arm_mask] = self.arms[arm].predict(arm_X_test)\n",
    "        return y_pred, arms\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335097    0\n",
       "239304    0\n",
       "372543    0\n",
       "214897    0\n",
       "485479    0\n",
       "         ..\n",
       "150160    0\n",
       "205126    0\n",
       "809270    0\n",
       "739403    0\n",
       "526654    0\n",
       "Name:  Label, Length: 633413, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed.y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
=======
   "execution_count": 24,
>>>>>>> a0d8df4fb78529c533d335cf14211b3ba57603fd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Cluster 0: 480204\n",
      "Training arm 0 on cluster 0\n",
      "Training arm 1 on cluster 0\n",
      "Training arm 2 on cluster 0\n",
      "Training arm 3 on cluster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\apollon\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arm 4 on cluster 0\n",
      "Cluster 1: 153209\n",
      "Training arm 0 on cluster 1\n",
      "Training arm 1 on cluster 1\n",
      "Training arm 2 on cluster 1\n",
      "Training arm 3 on cluster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\apollon\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arm 4 on cluster 1\n",
      "Setting reward_sums arm 0 on cluster 0\n",
      "Setting reward_sums arm 1 on cluster 0\n",
      "Setting reward_sums arm 2 on cluster 0\n",
      "Setting reward_sums arm 3 on cluster 0\n",
      "Setting reward_sums arm 4 on cluster 0\n",
      "Setting reward_sums arm 0 on cluster 1\n",
      "Setting reward_sums arm 1 on cluster 1\n",
      "Setting reward_sums arm 2 on cluster 1\n",
      "Setting reward_sums arm 3 on cluster 1\n",
      "Setting reward_sums arm 4 on cluster 1\n"
=======
      "Cluster 0: 2789828\n",
      "Training arm 0 on cluster 0\n",
      "Training arm 1 on cluster 0\n",
      "Training arm 2 on cluster 0\n",
      "Cluster 1: 377320\n",
      "Training arm 0 on cluster 1\n",
      "Training arm 1 on cluster 1\n",
      "Training arm 2 on cluster 1\n",
      "Setting reward_sums arm 0 on cluster 0\n",
      "Setting reward_sums arm 1 on cluster 0\n",
      "Setting reward_sums arm 2 on cluster 0\n",
      "Setting reward_sums arm 0 on cluster 1\n",
      "Setting reward_sums arm 1 on cluster 1\n",
      "Setting reward_sums arm 2 on cluster 1\n"
>>>>>>> a0d8df4fb78529c533d335cf14211b3ba57603fd
     ]
    }
   ],
   "source": [
    "# Train the MAB\n",
    "mab = MultiArmedBanditThompsonSampling(n_arms=3, n_clusters=2)\n",
    "mab.train(df_preprocessed.x_train, df_preprocessed.y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 25,
>>>>>>> a0d8df4fb78529c533d335cf14211b3ba57603fd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
<<<<<<< HEAD
      "           0       1.00      0.98      0.99    266649\n",
      "           1       0.40      0.91      0.55      4815\n",
      "\n",
      "    accuracy                           0.97    271464\n",
      "   macro avg       0.70      0.94      0.77    271464\n",
      "weighted avg       0.99      0.97      0.98    271464\n",
      "\n",
      "Accuracy: 0.9739523472725665\n",
      "Recall: 0.9419774679231379\n",
      "F1 Score: 0.7698520465263343\n",
      "ROC AUC Score: 0.9419774679231377\n"
     ]
    }
   ],
   "source": [
    "# Test the MAB\n",
    "\n",
    "\n",
    "y_pred, selected_arms = mab.predict(df_preprocessed.x_test)\n",
    "# Transform the y_pred values to 0 and 1 strings\n",
    "y_test = np.array([int(y) for y in df_preprocessed.y_test])\n",
    "y_pred = np.array([int(y) for y in y_pred])\n",
    "\n",
    "# Print y_pred unique values\n",
    "print(np.unique(y_pred))\n",
    "# Print y_test unique values\n",
    "print(np.unique(y_test))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = open(\"ARMS.txt\", \"a\")\n",
    "for i in range(y_pred.shape[0]):\n",
    "    v.write(\n",
    "        f\"Selected arm: {selected_arms[i]}\\tPredicted:{y_pred[i]}\\tActual:{y_test[i]}\")\n",
    "v.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
      "           0       0.56      0.94      0.70       602\n",
      "           1       1.00      1.00      1.00   1356748\n",
      "\n",
      "    accuracy                           1.00   1357350\n",
      "   macro avg       0.78      0.97      0.85   1357350\n",
      "weighted avg       1.00      1.00      1.00   1357350\n",
      "\n",
      "Accuracy: 0.9996507901425572\n",
      "Recall: 0.9691080561338743\n",
      "F1 Score: 0.852157034949286\n",
      "ROC AUC Score: 0.9691080561338742\n"
     ]
    }
   ],
   "source": [
    "# Test the MAB\n",
    "y_pred, selected_arms = mab.predict(df_preprocessed.x_test)\n",
    "# Transform the y_pred values to 0 and 1 strings\n",
    "y_test = np.array([int(y) for y in df_preprocessed.y_test])\n",
    "y_pred = np.array([int(y) for y in y_pred])\n",
    "\n",
    "# Print y_pred unique values\n",
    "print(np.unique(y_pred))\n",
    "# Print y_test unique values\n",
    "print(np.unique(y_test))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))"
   ]
>>>>>>> a0d8df4fb78529c533d335cf14211b3ba57603fd
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
